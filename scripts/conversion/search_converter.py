import re
import os
import sys
import argparse
from datetime import datetime
from typing import List

def convert_line_to_central(line_content: str) -> str:
    """PubMedå½¢å¼ã®è¡Œå†…å®¹ã‚’Cochrane CENTRALå½¢å¼ã«å¤‰æ›ã™ã‚‹"""
    processed_content = line_content
    
    # 1. è¿‘æ¥æ¤œç´¢å¤‰æ› (finditerã§å…¨ã¦ã®ãƒãƒƒãƒã‚’å–å¾—ã—ã€æœ«å°¾ã‹ã‚‰ç½®æ›)
    proximity_pattern = re.compile(r'("[^"]+")\[(ti|tiab|ad|Title|Title/Abstract|Affiliation):~(\d+)\]')
    proximity_matches = list(proximity_pattern.finditer(processed_content))
    for match in reversed(proximity_matches):
        terms = match.group(1).strip('"').split()  # "term1 term2" â†’ [term1, term2]
        field = match.group(2)                      # ti, tiab, ad ãªã©
        proximity = int(match.group(3))             # è¿‘æ¥å€¤N
        
        # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°
        if field in ['ti', 'Title']:
            central_field = ':ti'
        elif field in ['tiab', 'Title/Abstract']:
            central_field = ':ti,ab,kw'
        elif field in ['ad', 'Affiliation']:
            central_field = ''  # CENTRALã«ã¯å¯¾å¿œã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒãªã„
        else:
            central_field = ':ti,ab,kw'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        
        # è¿‘æ¥æ¼”ç®—å­å¤‰æ›
        if proximity == 0:
            # éš£æ¥ï¼ˆé–“ã«å˜èªãªã—ï¼‰
            quoted_terms = [f'"{term}"' for term in terms]
            central_proximity = ' NEXT '
            transformed_prox = f'({central_proximity.join(quoted_terms)}){central_field}'
        else:
            # Nèªä»¥å†…ã®è¿‘æ¥
            if len(terms) == 2:  # ç¾åœ¨ã®PubMedã§ã¯2å˜èªã®ã¿ã‚µãƒãƒ¼ãƒˆ
                transformed_prox = f'("{terms[0]}" NEAR/{proximity} "{terms[1]}"){central_field}'
            else:
                # è¤‡æ•°èªã®å ´åˆã¯ã€CENTRALå½¢å¼ã§é©åˆ‡ã«å¤‰æ›
                quoted_terms = [f'"{term}"' for term in terms]
                transformed_prox = f'({" AND ".join(quoted_terms)}){central_field}'
        
        start, end = match.span()
        processed_content = processed_content[:start] + transformed_prox + processed_content[end:]
    
    print(f"After Proximity (CENTRAL): {processed_content}")
    
    # 2. MeSHå¤‰æ› (finditerã§å…¨ã¦ã®ãƒãƒƒãƒã‚’å–å¾—ã—ã€æœ«å°¾ã‹ã‚‰ç½®æ›)
    mesh_pattern = re.compile(r'("([^"]+)")\[(Mesh|mh)\]')
    mesh_matches = list(mesh_pattern.finditer(processed_content))
    for match in reversed(mesh_matches):
        term_only = match.group(2)      # Term
        transformed_term = f'[mh "{term_only}"]'
        start, end = match.span()
        processed_content = processed_content[:start] + transformed_term + processed_content[end:]
    print(f"After MeSH (CENTRAL): {processed_content}")

    # 3. tiabå¤‰æ› (finditerã§å…¨ã¦ã®ãƒãƒƒãƒã‚’å–å¾—ã—ã€æœ«å°¾ã‹ã‚‰ç½®æ›)
    tiab_pattern = re.compile(r'((?:"[^"]+"|\S+?))\s*\[tiab\]') # ä¿®æ­£å¾Œã®ãƒ‘ã‚¿ãƒ¼ãƒ³
    tiab_matches = list(tiab_pattern.finditer(processed_content))
    for match in reversed(tiab_matches):
        term = match.group(1) # æ¤œç´¢èªéƒ¨åˆ†
        # CENTRALå½¢å¼ã§ã¯ã€æ¤œç´¢èªã«ãã®ã¾ã¾ :ti,ab,kw ã‚’ä»˜ä¸
        transformed_tiab = f'{term}:ti,ab,kw'
        
        start, end = match.span() # ãƒãƒƒãƒå…¨ä½“ã®ç¯„å›²ï¼ˆä¾‹: "term[tiab]"ï¼‰
        processed_content = processed_content[:start] + transformed_tiab + processed_content[end:]
    
    print(f"CENTRAL conversion result for '{line_content}': {processed_content}")
    return processed_content

def convert_to_central(pubmed_query: str) -> str:
    lines = pubmed_query.strip().split('\n')
    central_lines = []
    line_num_pattern = re.compile(r'^#(\d+)\s+(.*)$')
    for original_line in lines:
        line = original_line.strip()
        if not line:
            central_lines.append('')
            continue
        print(f"Processing CENTRAL line (raw): {line}")
        match_line_num = line_num_pattern.match(line)
        if match_line_num:
            num, content = match_line_num.groups()
            print(f"Found CENTRAL line number: #{num}, content: {content}")
            processed_content = convert_line_to_central(content)
            central_lines.append(f"#{num} {processed_content}")
        else:
            print(f"CENTRAL line without number (assuming combination): {line}")
            central_lines.append(line) 
    return '\n'.join(central_lines)

def normalize_pubmed_input(text: str) -> str:
    """PubMedæ¨™æº–å½¢å¼ã‚’å†…éƒ¨å‡¦ç†å½¢å¼ã«æ­£è¦åŒ–"""
    lines = text.strip().split('\n')
    normalized = []
    for line in lines:
        line = line.strip()
        if not line:
            normalized.append('')
            continue
        match = re.match(r'^(\d+)\.?\s+(.*)$', line)
        if match:
            normalized.append(f"#{match.group(1)} {match.group(2)}")
        else:
            normalized.append(line)
    return '\n'.join(normalized)

def validate_search_syntax(text: str) -> List[str]:
    """æ¤œç´¢å¼ã®æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯"""
    errors = []
    lines = text.strip().split('\n')
    for i, line in enumerate(lines, 1):
        line = line.strip()
        if not line:
            continue
        if re.match(r'^\d+\s+', line):
            errors.append(f"Line {i}: Missing period after line number '{line[:20]}...'")
        if 'exp ' in line and not line.endswith('/'):
            if not re.search(r'EMB\.EXACT\.EXPLODE', line):
                errors.append(f"Line {i}: MeSH term may be missing trailing slash: '{line[:30]}...'")
    return errors

def convert_line_to_dialog(line_content: str) -> str:
    """PubMedå½¢å¼ã®è¡Œå†…å®¹ã‚’Dialog (Embase)å½¢å¼ã«å¤‰æ›ã™ã‚‹"""
    processed_content = line_content
    
    exp_pattern = re.compile(r'exp\s+([^/]+)/')
    exp_matches = list(exp_pattern.finditer(processed_content))
    for match in reversed(exp_matches):
        term = match.group(1).strip()
        term_lower = term.lower()
        transformed_term = f'EMB.EXACT.EXPLODE("{term_lower}")'
        start, end = match.span()
        processed_content = processed_content[:start] + transformed_term + processed_content[end:]
    
    tw_pattern = re.compile(r'([^.]+)\.tw\.')
    tw_matches = list(tw_pattern.finditer(processed_content))
    for match in reversed(tw_matches):
        term = match.group(1).strip()
        if term.startswith('(') and term.endswith(')'):
            transformed_tw = f'(TI{term} OR AB{term})'
        else:
            transformed_tw = f'(TI({term}) OR AB({term}))'
        start, end = match.span()
        processed_content = processed_content[:start] + transformed_tw + processed_content[end:]
    
    tiab_simple_pattern = re.compile(r'([^.]+)\.ti,ab\.')
    tiab_simple_matches = list(tiab_simple_pattern.finditer(processed_content))
    for match in reversed(tiab_simple_matches):
        term = match.group(1).strip()
        transformed_tiab = f'(TI({term}) OR AB({term}))'
        start, end = match.span()
        processed_content = processed_content[:start] + transformed_tiab + processed_content[end:]
    
    processed_content = re.sub(r'adj(\d+)', r'NEAR/\1', processed_content)
    
    # 1. è¿‘æ¥æ¤œç´¢å¤‰æ›
    proximity_pattern = re.compile(r'("[^"]+")\[(ti|tiab|ad|Title|Title/Abstract|Affiliation):~(\d+)\]')
    proximity_matches = list(proximity_pattern.finditer(processed_content))
    for match in reversed(proximity_matches):
        terms = match.group(1).strip('"').split()  # "term1 term2" â†’ [term1, term2]
        field = match.group(2)                      # ti, tiab, ad ãªã©
        proximity = int(match.group(3))             # è¿‘æ¥å€¤N
        
        # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°
        if field in ['ti', 'Title']:
            dialog_field = 'TI'
        elif field in ['tiab', 'Title/Abstract']:
            dialog_field = 'TI,AB'
        elif field in ['ad', 'Affiliation']:
            dialog_field = 'CS'  # æ‰€å±æ©Ÿé–¢ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
        else:
            dialog_field = 'TI,AB'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        
        # è¿‘æ¥æ¼”ç®—å­å¤‰æ›
        if len(terms) == 2:  # ç¾åœ¨ã®PubMedã§ã¯2å˜èªã®ã¿ã‚µãƒãƒ¼ãƒˆ
            if proximity == 0:
                # éš£æ¥ï¼ˆé–“ã«å˜èªãªã—ï¼‰- W/1ï¼ˆé †åºå›ºå®šã§1å˜èªä»¥å†…ï¼‰
                transformed_prox = f'{dialog_field}({terms[0]} W/1 {terms[1]})'
            else:
                # Nèªä»¥å†…ã®è¿‘æ¥ - N/nï¼ˆé †åºä¸åŒã§nå˜èªä»¥å†…ï¼‰
                transformed_prox = f'{dialog_field}({terms[0]} N/{proximity} {terms[1]})'
        else:
            # è¤‡æ•°èªã®å ´åˆã¯ã€Dialogå½¢å¼ã§é©åˆ‡ã«å¤‰æ›ï¼ˆANDã§çµåˆï¼‰
            transformed_prox = f'{dialog_field}({" AND ".join(terms)})'
        
        start, end = match.span()
        processed_content = processed_content[:start] + transformed_prox + processed_content[end:]
    
    print(f"After Proximity (Dialog): {processed_content}")
    
    # 2. MeSHå¤‰æ›
    mesh_pattern = re.compile(r'("([^"]+)")\[(Mesh|mh)\]')
    mesh_matches = list(mesh_pattern.finditer(processed_content))
    for match in reversed(mesh_matches):
        term_only = match.group(2)
        transformed_term = f'EMB.EXACT.EXPLODE("{term_only}")'
        start, end = match.span()
        processed_content = processed_content[:start] + transformed_term + processed_content[end:]
    print(f"After MeSH (Dialog): {processed_content}")

    # 2. tiabå¤‰æ›
    tiab_pattern = re.compile(r'((?:"[^"]+"|\S+?))\s*\[tiab\]') # ä¿®æ­£å¾Œã®ãƒ‘ã‚¿ãƒ¼ãƒ³
    tiab_matches = list(tiab_pattern.finditer(processed_content))
    for match in reversed(tiab_matches):
        term = match.group(1) # æ¤œç´¢èªéƒ¨åˆ†
        # Dialogå½¢å¼ã§ã¯ã€TI(æ¤œç´¢èª) OR AB(æ¤œç´¢èª)
        # æ¤œç´¢èªãŒãƒ€ãƒ–ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆã§å›²ã¾ã‚Œã¦ã„ãªã„å ´åˆã€Dialogã®TI/ABå†…ã§ã¯ãƒ€ãƒ–ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆã§å›²ã‚€ã®ãŒä¸€èˆ¬çš„
        if term.startswith('"') and term.endswith('"'):
            transformed_tiab = f'(TI({term}) OR AB({term}))'
        else:
            transformed_tiab = f'(TI("{term}") OR AB("{term}"))'
        
        start, end = match.span() # ãƒãƒƒãƒå…¨ä½“ã®ç¯„å›²ï¼ˆä¾‹: "term[tiab]"ï¼‰
        processed_content = processed_content[:start] + transformed_tiab + processed_content[end:]
    print(f"After tiab (Dialog): {processed_content}")

    # 3. æ—¥ä»˜ç¯„å›²ã®å¤‰æ›
    date_pattern = re.compile(r'(\d{4})/(\d{1,2})/(\d{1,2}):(\d{4})/(\d{1,2})/(\d{1,2})\[DP\]')
    processed_content = date_pattern.sub(lambda m: f"PD({m.group(1)}{m.group(2).zfill(2)}{m.group(3).zfill(2)}-{m.group(4)}{m.group(5).zfill(2)}{m.group(6).zfill(2)})", processed_content)
    
    print(f"Dialog line conversion result for '{line_content}': {processed_content}")
    return processed_content

def convert_to_dialog(pubmed_query: str) -> str:
    normalized_query = normalize_pubmed_input(pubmed_query)
    
    syntax_errors = validate_search_syntax(pubmed_query)
    if syntax_errors:
        print("âš ï¸  æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ:")
        for error in syntax_errors:
            print(f"   {error}")
        print("   å¤‰æ›ã‚’ç¶šè¡Œã—ã¾ã™ãŒã€çµæœã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n")
    
    lines = normalized_query.strip().split('\n')
    dialog_lines = []
    line_counter = 1
    line_mapping = {} 
    line_num_pattern = re.compile(r'^#(\d+)\s+(.*)$')

    temp_converted_lines = []
    for original_line in lines:
        line = original_line.strip()
        if not line:
            temp_converted_lines.append("")
            continue
        print(f"Dialog processing line (raw): {line}")
        match_line_num = line_num_pattern.match(line)
        if match_line_num:
            pubmed_num, content = match_line_num.groups()
            dialog_s_num = f"S{line_counter}"
            line_mapping[f"#{pubmed_num}"] = dialog_s_num
            print(f"Found Dialog line number: #{pubmed_num} -> {dialog_s_num}, content: {content}")
            converted_content = convert_line_to_dialog(content)
            temp_converted_lines.append(f"{dialog_s_num} {converted_content}")
            line_counter += 1
        else:
            print(f"Dialog line without number (assuming combination): {line}")
            temp_converted_lines.append(line)

    final_dialog_lines = []
    for line_to_process_refs in temp_converted_lines:
        final_line = line_to_process_refs
        sorted_refs = sorted(line_mapping.items(), key=lambda item: len(item[0]), reverse=True)
        for pubmed_ref, dialog_ref in sorted_refs:
            # #è¨˜å·ã§å§‹ã¾ã‚Šã€æ•°å­—ãŒç¶šããƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ­£ç¢ºã«ãƒãƒƒãƒã•ã›ã‚‹
            pattern = r'(?<![a-zA-Z0-9_#])' + re.escape(pubmed_ref) + r'(?![a-zA-Z0-9_])'
            final_line = re.sub(pattern, dialog_ref, final_line)
        final_dialog_lines.append(final_line)
        
    return '\n'.join(final_dialog_lines)

def save_to_file(project_dir, content, filename):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã—ãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜ã™ã‚‹ã€‚ãƒ‘ã‚¹ã®æ­£è¦åŒ–ã¨ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ã‚’è¿½åŠ """
    # ãƒ‘ã‚¹ã®æ­£è¦åŒ–ï¼ˆWindowsã§ã®ãƒ‘ã‚¹åŒºåˆ‡ã‚Šæ–‡å­—ã®å•é¡Œå¯¾å¿œï¼‰
    project_dir = os.path.normpath(project_dir)
    os.makedirs(project_dir, exist_ok=True)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®æ§‹ç¯‰ã¨æ­£è¦åŒ–
    filepath = os.path.normpath(os.path.join(project_dir, filename))
    print(f"ä¿å­˜å…ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: {filepath}")
    
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜æˆåŠŸ: {filepath}")
        # ä¿å­˜ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
        if os.path.exists(filepath):
            print(f"ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª: {filepath} ãŒæ­£å¸¸ã«ä½œæˆã•ã‚Œã¾ã—ãŸ")
        else:
            print(f"è­¦å‘Š: ãƒ•ã‚¡ã‚¤ãƒ« {filepath} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    except Exception as e:
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
        raise
    
    return filepath

def main():
    parser = argparse.ArgumentParser(description='PubMedæ¤œç´¢å¼ã‚’CENTRALã¨Dialogå½¢å¼ã«å¤‰æ›ã™ã‚‹ãƒ„ãƒ¼ãƒ«')
    parser.add_argument('input', nargs='?', help='PubMedæ¤œç´¢å¼ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæŒ‡å®šãŒãªã‘ã‚Œã°æ¨™æº–å…¥åŠ›ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼‰')
    parser.add_argument('--project', '-p', default=None, help='ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåï¼ˆsearch_formula/é…ä¸‹ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåï¼‰')
    parser.add_argument('--validate-only', action='store_true', help='æ§‹æ–‡ãƒã‚§ãƒƒã‚¯ã®ã¿å®Ÿè¡Œï¼ˆå¤‰æ›ã¯è¡Œã‚ãªã„ï¼‰')
    args = parser.parse_args()
    text = ""
    if args.input:
        try:
            with open(args.input, 'r', encoding='utf-8') as f:
                text = f.read()
        except Exception as e:
            print(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
            return
    else:
        print("PubMedæ¤œç´¢å¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆçµ‚äº†ã™ã‚‹ã«ã¯ Ctrl+D ã¾ãŸã¯ Ctrl+Z ã‚’æŠ¼ã—ã¦ãã ã•ã„ï¼‰:")
        text = sys.stdin.read()
    
    if args.validate_only:
        print("ğŸ” æ§‹æ–‡ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œä¸­...")
        syntax_errors = validate_search_syntax(text)
        if syntax_errors:
            print("âŒ æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ:")
            for error in syntax_errors:
                print(f"   {error}")
            return
        else:
            print("âœ… æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
            return
    
    project_name = args.project if args.project else f"project_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    project_dir = os.path.join("search_formula", project_name)
    os.makedirs(project_dir, exist_ok=True)
    print(f"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {project_dir}")
    
    print("\nCENTRALå½¢å¼ã«å¤‰æ›ä¸­...")
    central_query = convert_to_central(text)
    
    print("\nDialog(Embase)å½¢å¼ã«å¤‰æ›ä¸­...")
    dialog_query = convert_to_dialog(text)
    
    md_content = f"# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ¥æ¤œç´¢å¼\n\nå¤‰æ›æ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
    md_content += f"## PubMed\n\n```\n{text}\n```\n\n"
    md_content += f"## Cochrane CENTRAL\n\n```\n{central_query}\n```\n\n"
    md_content += f"## Dialog (Embase)\n\n```\n{dialog_query}\n```\n\n"
    
    cmdline_lines = []
    for line_content in dialog_query.split('\n'):
        stripped_line = line_content.strip()
        if stripped_line:
            match_s_num_content = re.match(r'^S\d+\s+(.*)$', stripped_line)
            if match_s_num_content:
                cmdline_lines.append(match_s_num_content.group(1).strip())
            elif not stripped_line.startswith('#') and not re.match(r'^S\d+\s*$', stripped_line):
                 cmdline_lines.append(stripped_line)

    md_content += "## Command Line for Dialog\n\nDialogæ¤œç´¢ç”»é¢ã§ã‚³ãƒ”ãƒ¼&ãƒšãƒ¼ã‚¹ãƒˆã—ã¦ä½¿ç”¨ã™ã‚‹ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å½¢å¼ï¼š\n\n```\n"
    md_content += '\n'.join(cmdline_lines)
    md_content += "\n```\n"
    
    all_search_file = save_to_file(project_dir, md_content, "all_database_search.md")
    print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç”¨æ¤œç´¢å¼ã‚’ã¾ã¨ã‚ã¦ä¿å­˜ã—ã¾ã—ãŸ: {all_search_file}")
    
    print("\nå‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nå‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚")
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
